# -*- coding: utf-8 -*-
"""transfer_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UzvNhdidzALl6II2X9yCkObdK7GlWSYQ

# Transfer Learning with tensorflow:
## Part 1 Feature Extraction


---

The main benefits of using transfer learning:
1. Can leverage existing neural networks that have been proven to work 
2. Can leverage a working neural network architecture which has already learned patterns with similar data to our own.

### Imports
"""

import numpy as np
import pandas as pd

import matplotlib.image as mpimg
import matplotlib.pyplot as plt


import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator


import pathlib
import zipfile
import os
import random
import datetime

"""### Download data"""

# Download 10 percent of the 10 food classes dataset
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip

# Unzip downloaded data
zip_ref = zipfile.ZipFile('10_food_classes_10_percent.zip')
zip_ref.extractall()
zip_ref.close()

# How many images are there in each folder
for dirpath,dirnames, filenames in os.walk('/content/10_food_classes_10_percent'):
  if len(dirnames) == 0:
    print(f"There are {len(filenames)} images in {dirpath} ")
  else:
    print(f"There are {len(dirnames)} directories in {dirpath}")

# Get the subdirectories (class_names)
data_dir = pathlib.Path('10_food_classes_10_percent/train')
class_names = np.array(sorted(item.name for item in data_dir.glob("*")))
print(class_names)

# Function to view random images
def view_random_image(target_dir,target_class):
  """
  Gets a random image from a selected directory and calss
  """
  target_folder = target_dir + "/" + target_class
  random_image = random.sample(os.listdir(target_folder),1)

  # Plot out the image
  img = mpimg.imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off")
  print(f"Image shape: {img.shape}")
  
  return img

# Plot a random image for each class
def view_images(target_dir):
  """
  Plots a random image from each class
  """
  plt.figure(figsize=(15,15))
  for i in range(len(class_names)):
    plt.subplot(5,5,i+1)
    target_folder = target_dir + "/" + class_names[i]
    random_image = random.sample(os.listdir(target_folder),1)
    img = mpimg.imread(target_folder + "/" + random_image[0])
    plt.imshow(img)
    plt.axis("off")
    img_info = class_names[i] + "\n" + str(img.shape)
    plt.title(img_info)

img = view_random_image(target_dir = '10_food_classes_10_percent/test',
                        target_class = 'sushi')

view_images(target_dir = "10_food_classes_10_percent/train")

"""## Creating data loaders (preparing the data)
we will prepare the data using tf keras ImageDataGenerator
"""

# Setup global variables
IMAGE_SHAPE = (224,224)
BATCH_SIZE = 32
EPOCHS = 5


# Setup data
train_dir = "10_food_classes_10_percent/train/"
test_dir = "10_food_classes_10_percent/test/"

train_datagen = ImageDataGenerator(rescale = 1/255.)
test_datagen = ImageDataGenerator(rescale = 1/255.)

train_data_10_percent = train_datagen.flow_from_directory(train_dir,
                                                          target_size = IMAGE_SHAPE,
                                                          batch_size = BATCH_SIZE,
                                                          class_mode = "categorical")


test_data_10_percent = test_datagen.flow_from_directory(test_dir,
                                                        target_size = IMAGE_SHAPE,
                                                        batch_size = BATCH_SIZE,
                                                        class_mode = "categorical")

"""## Setting up callbacks
Call can be used for
* Tracking experiments with tensorboard
* Model checkpoint
* Stopping a model from overtraining

"""

# Create tensorboard callback 
# We wil make it into a function in order to use it for multiple models

def create_tensorboard_callback(dir_name, experiment_name):
  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%d-%m-%Y|%H:%M")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(
      log_dir=log_dir
  )
  print(f"Saving TensorBoard log files to: {log_dir}")
  return tensorboard_callback

"""## Creating the model using tensorflow hub
We are going to use and compare 2 models

"""

resnet_url = "https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4"

efficient_url = "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1"

# Lets make a function to create a model from a url
def create_model(model_url,num_classes=10):
  """
  Creates a keras model from a tfhub url
  Also gets number of classes needed ,default = 10
  
  Retruns:
    An uncompiled Keras sequential model with model_ulr as feature extractor layer
    and Dense output layer with num classes output neurons
  """
  # Download the pretained model and save it as a kera layers
  feature_extractor_layer = hub.KerasLayer(model_url,
                                           trainable = False,
                                           name = "feature_extraction_layer",
                                           input_shape = IMAGE_SHAPE+(3,))
  
  # Create our own model
  model = tf.keras.Sequential([
    feature_extractor_layer,
    layers.Dense(num_classes,activation="softmax",name="Output_layer")
  ])


  return model

# Create model
resnet_model = create_model(resnet_url)

# Compile
resnet_model.compile(loss='categorical_crossentropy',
                     optimizer=tf.keras.optimizers.Adam(),
                     metrics=['accuracy'])

# Lets fit the model to the data
resnet_history = resnet_model.fit(train_data_10_percent,
                                  epochs=5,
                                  steps_per_epoch=len(train_data_10_percent),
                                  validation_data=test_data_10_percent,
                                  validation_steps=len(test_data_10_percent),
                                  # Add TensorBoard callback to model (callbacks parameter takes a list)
                                  callbacks=[create_tensorboard_callback(dir_name="tensorflow_hub", # save experiment logs here
                                                                         experiment_name="resnet50V2")]) # name of log files

def plot_loss_curves(history):
  """
  Plots out separate loss curves for training and validation data
  """
  loss = history.history["loss"]
  val_loss = history.history["val_loss"]

  accuracy = history.history["accuracy"]
  val_accuracy = history.history["val_accuracy"]

  epochs = range(len(history.history["loss"]))

  # Plot the loss
  plt.plot(epochs,loss,label="training loss")
  plt.plot(epochs,val_loss,label= "validation loss")
  plt.title("Loss")
  plt.xlabel("Epochs")
  plt.legend()

  # Plot out the accuracy
  plt.figure()
  plt.plot(epochs,accuracy,label="Training accuracy")
  plt.plot(epochs,val_accuracy,label="Validation accuracy")
  plt.title("Accuracy")
  plt.xlabel("Epochs")
  plt.legend();

plot_loss_curves(resnet_history)

"""## Time to try again this time with the efficient net b0 feature extraction model"""

# Create and compile model
efficientnet_model = create_model(efficient_url)


efficientnet_model.compile(loss='categorical_crossentropy',
                     optimizer=tf.keras.optimizers.Adam(),
                     metrics=['accuracy'])

# Lets fit the model to the data
efficient_history = efficientnet_model.fit(train_data_10_percent,
                                  epochs=5,
                                  steps_per_epoch=len(train_data_10_percent),
                                  validation_data=test_data_10_percent,
                                  validation_steps=len(test_data_10_percent),
                                  # Add TensorBoard callback to model (callbacks parameter takes a list)
                                  callbacks=[create_tensorboard_callback(dir_name="tensorflow_hub", # save experiment logs here
                                                                         experiment_name="efficientnetb0")]) # name of log files

plot_loss_curves(efficient_history)

efficientnet_model.summary()

resnet_model.summary()

"""## There are different types of transfer learning
* `As is`: learning using an existing model with no changes
* `Feature extraction`: use the prelearned patterns of an existing model and adjusting the output layer for our own problem
* `Fine tuning` : Use the prelearned patterns of an existing model and fine tuning many or all of the underlying layers including new output layers.

## Comparing our models using Tensorboard
"""

# Upload tensorboard dev records
 !tensorboard dev upload --logdir ./tensorflow_hub/ \
  --name "EfficientNetB0 vs ResNet50V2" \
  --description "Comparing two different Tensorflow hub models on 10 percent of 10 food classes" \
  --one_shot

"""### Public link of tensorflow hub uploaded models: https://tensorboard.dev/experiment/UKGs49o8QlWekmW6OLT3ug/"""

!tensorboard dev list

# How to delete an experiment
# !tensorboard dev delete --experiment_id XXXXXXXXXXXX ## Experiment ID

