# -*- coding: utf-8 -*-
"""Transfer_Learning_Example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16I-3DmFvi9thenUBi-0UA4gebmFDaJdm

## Imports
"""

import numpy as np
import pandas as pd

import matplotlib.image as mpimg
import matplotlib.pyplot as plt


import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
 

import pathlib
import zipfile
import os
import random
import datetime

from google.colab import files
files.upload()

# Check if you upload successful
!ls -lha kaggle.json
# Output: -rw-r--r-- 1 root root 63 Aug  8 11:17 kaggle.json

# Install kaggle package
!pip install -q kaggle

"""## Make kaggle directory and download dataset"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Start to download dataset
!kaggle datasets download -d prasunroy/natural-images

"""## Unzip and view dataset"""

zip_ref = zipfile.ZipFile("natural-images.zip")
zip_ref.extractall()
zip_ref.close()

# How many images in each folder
for dirpath,dirnames,filenames in os.walk('/content/natural_images'):
  if len(dirnames) == 0:
    print(f"There are {len(filenames)} images in {dirpath} ")
  else:
    print(f"There are {len(dirnames)} directories in {dirpath}")

# Get the subdirectories (class_names)
data_dir = pathlib.Path('/content/natural_images')
class_names = np.array(sorted(item.name for item in data_dir.glob("*")))
print(class_names)

"""## Functions"""

# Make a function to view random images for each class
def view_images(target_dir):
  """
  Plots out a random image for each class
  """
  plt.figure(figsize=(15,15))
  for i in range(len(class_names)):
    plt.subplot(4,4,i+1)
    target_folder = target_dir + "/" + class_names[i]
    random_image = random.sample(os.listdir(target_folder),1)
    img = mpimg.imread(target_folder + "/" + random_image[0])
    plt.imshow(img)
    plt.axis("off")
    img_info = class_names[i] + "\n" + str(img.shape)
    plt.title(img_info)

def create_tensorboard_callback(dir_name,experiment_name):
  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%d-%m-%Y|%H:%M")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(
      log_dir = log_dir
  )
  print(f"Saving Tensorboard experiment log files to : {log_dir}")
  return tensorboard_callback

# Lets make a function to create a model from url
def create_model(model_url,num_classes = len(class_names)):
  """
  Creates a keras model from a tf hub url

  Returns:
    An uncompiled Keras sequential model
  """
  # Download the pretained model and save it as a keras layer
  feature_extractor_layer = hub.KerasLayer(model_url,
                                           trainable = False,
                                           name = "feature_extractor_layer",
                                           input_shape = IMAGE_SHAPE + (3,))
  
  # Create our own model
  model = tf.keras.Sequential([
    feature_extractor_layer,
    layers.Dense(num_classes,activation="softmax",name="Output_layer")
  ])
  return model

# Function to view loss and accuracy of a model
def plot_loss_curves(history):
  """
  Plots out separate loss curves for training and validation data
  """
  loss = history.history["loss"]
  accuracy = history.history["accuracy"]
  epochs = range(len(history.history["loss"]))

  # Plot the loss
  plt.plot(epochs,loss,label="training loss")
  plt.title("Loss")
  plt.xlabel("Epochs")
  plt.legend()

  # Plot out the accuracy
  plt.figure()
  plt.plot(epochs,accuracy,label="Training accuracy")
  plt.title("Accuracy")
  plt.xlabel("Epochs")
  plt.legend();

view_images("/content/natural_images")

"""## Setting up data for the model training"""

# Setup global variables
IMAGE_SHAPE = (512,512)
BATCH_SIZE = 32
EPOCHS = 2

train_dir = "/content/natural_images"

train_datagen = ImageDataGenerator(rescale = 1/255.)

train_data = train_datagen.flow_from_directory(train_dir,
                                               target_size = IMAGE_SHAPE,
                                               batch_size = BATCH_SIZE,
                                               class_mode = "categorical")

efficientnet_url = "https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1"

# Create model
efficientnet_model = create_model(model_url = efficientnet_url)

# Compile the model
efficientnet_model.compile(loss = "categorical_crossentropy",
                           optimizer = tf.keras.optimizers.Adam(),
                           metrics = ["accuracy"])

efficient_history = efficientnet_model.fit(train_data,
                                           epochs = EPOCHS,
                                           steps_per_epoch = len(train_data),
                                           callbacks = [create_tensorboard_callback(dir_name= "Tf_hub_models",
                                                                                    experiment_name = "efficientnetB7V1")])

plot_loss_curves(efficient_history)

efficientnet_model.summary()

"""## Time to test our model on some new unseen data

First lets create some functions to help us out
"""

def load_and_prep_image(filename,image_shape = 512,scale = True):
  """
  Reads an image from a filename and turns it into a tensor 
  Reshapes the image into 224 by default
  Rescales the image into 0 and 1 by default
  """
  # Read the image 
  img = tf.io.read_file(filename)
  # Decode it into a tensor
  img = tf.image.decode_jpeg(img)
  # Resize the image
  img = tf.image.resize(img , [image_shape,image_shape])
  img = img/255.
  return img

def pred_and_plot(model,file_path,class_names):
  """
  Predicts and plots customs images from a directory
  """
  # Setup figure size
  plt.figure(figsize=(20,20))
  # Get all the filenames under the file path
  filenames = os.listdir(file_path)

  # Get the image from the file path
  for i in range(len(filenames)):
    img = load_and_prep_image(file_path + "/" + filenames[i])
    # Make a prediction using the model on the img
    pred = model.predict(tf.expand_dims(img,axis=0))
      
    # Get the predicted class
    if len(pred[0] > 1): # Check for multi class labels
      pred_class = class_names[pred.argmax()] # If more than 2 labels take the max
    else:
      pred_class = class_names[int(tf.round(pred[0][0]))] # If only one output round them

    # Plot out the image
    plt.subplot(5,5,i + 1)
    plt.imshow(img)
    plt.title(f"Prediction: \n {pred_class}")
    plt.axis("off")

pred_and_plot(model = efficientnet_model,
              file_path = '/content/drive/MyDrive/machine_learning/natural_images',
              class_names = class_names)

